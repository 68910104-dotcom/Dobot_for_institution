import cv2
import torch
from torchvision import transforms
from PIL import Image
import os
from models2.models import Generator  # ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°: Generator ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

def process_folder_to_cartoon(input_dir, output_dir):
    """
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô input_dir ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• P2LDGAN ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô output_dir
    """
    
    # --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ---
    model_path = r"E:\P2LDGAN\p2ldgan_generator_200.pth"  # ‡πÉ‡∏™‡πà path checkpoint ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Generator ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Checkpoint
    try:
        generator = Generator().to(device)
        checkpoint = torch.load(model_path, map_location=device)
        generator.load_state_dict(checkpoint)
        generator.eval()
        print("‚úÖ Loaded checkpoint successfully.")
    except Exception as e:
        print(f"‚ùå Error loading model or checkpoint: {e}")
        return

    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Transformation
    transform = transforms.Compose([
        transforms.Resize((256, 256)),  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ])

    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Output
    os.makedirs(output_dir, exist_ok=True)
    print(f"üìÅ Output will be saved to: {output_dir}")

    # --- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ---
    
    # 4. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Input
    for filename in os.listdir(input_dir):
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (jpg, jpeg, png)
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            
            img_path = os.path.join(input_dir, filename)
            print(f"\nüñºÔ∏è Processing: {filename}")
            
            try:
                # ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ PIL (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö transforms)
                input_img = Image.open(img_path).convert("RGB")
            except Exception as e:
                print(f"‚ùå Error opening {filename}: {e}")
                continue
                
            # 5. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Input Tensor
            input_tensor = transform(input_img).unsqueeze(0).to(device)

            # 6. Generate output
            with torch.no_grad():
                output_tensor = generator(input_tensor)
                # Denormalize: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô [-1, 1] ‡πÄ‡∏õ‡πá‡∏ô [0, 1]
                output_tensor = (output_tensor * 0.5 + 0.5).clamp(0, 1)

            # 7. ‡πÅ‡∏õ‡∏•‡∏á Tensor ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô PIL Image ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
            output_img = transforms.ToPILImage()(output_tensor.squeeze().cpu())
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output
            output_filename = os.path.join(output_dir, f"cartoon_{filename}")
            output_img.save(output_filename)
            print(f"‚úÖ Generated image saved as {output_filename}")


# --- ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô ---

if __name__ == '__main__':
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    input_folder = "cropped_parts"  # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ 256x256 ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å crop
    output_folder = "cartoon_output" # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

    process_folder_to_cartoon(input_folder, output_folder)
